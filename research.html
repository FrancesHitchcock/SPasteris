<DOCTYPE html>
<html lang="en">
	<head>
		<title>Stephen Pasteris Research</title>
		<meta charset="utf-8"/>
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<link rel="stylesheet" href="Resources/Stylesheet/reset.css"/>
		<link rel="stylesheet" href="Resources/Stylesheet/Stephen_styling.css"/>	
	</head>
	<body>
		<div class="container">
			<nav class="banner">
				<h1 id="name-big-screen">Stephen<br> Pasteris</h1>
				<span id="name-small-screen">Stephen Pasteris</span>
				<ul class="menu" id="res_menu">
					<li id="home_item"><a href="index.html">home<a></li>
					<li id="quals_item"><a href="qualifications.html">qualifications<a></li>
					<li id="research_item"><a href="#">research<a></li>
					<li id="pubs_item"><a href="publications.html">publications<a></li>				
				</ul>
			</nav>
			<header class="main_header" id="res_header">
				<img id="trees_pic" src="Resources/Images/trees.jpg" alt="Trees">
			</header>
			<article class="main_info" id="res_info">
				<table id="res_table">
					<caption><span id="research_title">Research</span><br><h3>Click on the titles to view the papers. For a full list of published papers please visit the <i>publications</i> page.</h3></caption>
					<tr>
						<th id="res_col1">Research Area</th>
						<th id="res_col2">Publications by Area</th>
					</tr>

					<tr>
						<td class="res_first_col"><span class="subtitle">Online Learning:</span><br>
						Online Learning is learning by 'trial and error'. Here, the learning process proceeds in a sequence of trials, on each of which an action is performed by the user or 'learner'. A loss is then incurred as a result of that action. At the end of each trial information on the losses relating to the different actions on that trial is revealed to the learner. The learner's aim is to suffer low cumulative loss.
						</td>
						<td class="papers"><br><a class="res_paper_link" href="https://proceedings.neurips.cc/paper/2021/file/124461dcd3571e6674ec4e0e140cc298-Paper.pdf" target="_blank">A Gang of Adversarial Bandits</a><br>
						<a class="res_paper_link" href="https://proceedings.neurips.cc/paper/2021/file/4a5876b450b45371f6cfe5047ac8cd45-Paper.pdf" target="_blank">Cooperative Stochastic Bandits With Asynchronous Agents and Constrained Feedback</a>
						<a class="res_paper_link" href="https://arxiv.org/pdf/2007.02801.pdf" target="_blank">Online Learning of Facility Locations</a><br>
						<a class="res_paper_link" href="https://arxiv.org/pdf/2008.07055.pdf" target="_blank">Online Multitask Learning with Long-Term Memory</a><br>
						<a class="res_paper_link" href="https://arxiv.org/pdf/1906.07255.pdf" target="_blank">Online Matrix Completion with Side Information</a></br>
						<a class="res_paper_link" href="https://arxiv.org/pdf/1810.11843.pdf" target="_blank">MaxHedge: Maximising a Maximum Online</a></br>
						<a class="res_paper_link" href="https://papers.nips.cc/paper/2016/file/d46e1fcf4c07ce4a69ee07e4134bcef1-Paper.pdf" target="_blank">Mistake Bounds for Binary Matrix Completion</a></br>	
						<a class="res_paper_link" href="https://papers.nips.cc/paper/2015/file/cdf1035c34ec380218a8cc9a43d438f9-Paper.pdf" target="_blank">Online Prediction at the Limit of Zero Temperature</a></br>
						<a class="res_paper_link" href="https://www.jmlr.org/papers/volume16/herbster15a/herbster15a.pdf" target="_blank">Predicting a Switching Sequence of Graph Labelings</a></br>
						<a class="res_paper_link" href="http://proceedings.mlr.press/v30/Gentile13.pdf" target="_blank">Online Similarity Prediction of Networked Data from Known and Unknown Graphs</a></br>
						<a class="res_paper_link" href="https://papers.nips.cc/paper/2012/file/e2c4a40d50b47094f571e40efead3900-Paper.pdf" target="_blank">Online Sum-Product Computation over Trees</a></br>
						<a class="res_paper_link" href="http://www0.cs.ucl.ac.uk/staff/M.Herbster/pubs/mc14.pdf" target="_blank">Efficient Prediction for Tree Markov Random Fields in a Streaming Model</a></td>

					</tr>
					<tr>
						<td colspan="2" class="phi_cell"><span class="phi">Φ</span><br></td>					
					</tr>
					<tr>
						<td class="res_first_col"><span class="subtitle">Bandits:</span><br>
						Bandit problems are a type of online learning in which, after an action has been selected on a trial, the loss associated only with that particular action on the trial is revealed. This is as opposed to full-information problems in which the losses of all actions are revealed.
						</td>
						<td class="papers"><br><a class="res_paper_link" href="https://proceedings.neurips.cc/paper/2021/file/124461dcd3571e6674ec4e0e140cc298-Paper.pdf" target="_blank">A Gang of Adversarial Bandits</a><br>
						<a class="res_paper_link" href="https://proceedings.neurips.cc/paper/2021/file/4a5876b450b45371f6cfe5047ac8cd45-Paper.pdf" target="_blank">Cooperative Stochastic Bandits With Asynchronous Agents and Constrained Feedback</a><td>
					
					</tr>
					<tr>
						<td colspan="2" class="phi_cell"><span class="phi">Φ</span><br></td>					
					</tr>
					
					<tr>
						<td class="res_first_col"><span class="subtitle">Non-Stationary Learning:</span><br>
						Non-Stationary Learning is essentially Online Learning but in an environment which is changing in a way which is unseen by the learner. In regular Online Learning the aim is to minimise the difference between the learner's cumulative loss and the cumulative loss which would have been obtained as a result of consistently choosing a particular action on every trial. In Non-Stationary Online Learning we instead compare the learner's cumulative loss to that obtained by the comparator action changing over the sequence of trials.
						</td>
						<td class="papers"><br><a class="res_paper_link" href="https://arxiv.org/pdf/2008.07055.pdf" target="_blank">Online Multitask Learning with Long-Term Memory</a><br>
						<a class="res_paper_link" href="https://www.jmlr.org/papers/volume16/herbster15a/herbster15a.pdf" target="_blank">Predicting a Switching Sequence of Graph Labelings</a><td>
					
					</tr>
					<tr>
						<td colspan="2" class="phi_cell"><span class="phi">Φ</span><br></td>					
					</tr>
					
					<tr>
						<td class="res_first_col"><span class="subtitle">Classification:</span><br>
						Classification problems are those in which a label is required to be assigned to each item within a set.  We call a set of all items with the same label a 'class'. In order for the learner to assign the labels some of those labels are provided <i>a priori</i>. For example: the items could be names of people and the corresponding labels their favourite music genres; alternatively, items could be images of animals and the labels the name of the species.
						</td>
						<td class="papers"><br><a class="res_paper_link" href="https://arxiv.org/pdf/1906.07255.pdf" target="_blank">Online Matrix Completion with Side Information</a><br>
						<a class="res_paper_link" href="https://papers.nips.cc/paper/2016/file/d46e1fcf4c07ce4a69ee07e4134bcef1-Paper.pdf" target="_blank">Mistake Bounds for Binary Matrix Completion</a><br>
						<a class="res_paper_link" href="https://papers.nips.cc/paper/2015/file/cdf1035c34ec380218a8cc9a43d438f9-Paper.pdf" target="_blank">Online Prediction at the Limit of Zero Temperature</a></br>
						<a class="res_paper_link" href="https://www.jmlr.org/papers/volume16/herbster15a/herbster15a.pdf" target="_blank">Predicting a Switching Sequence of Graph Labelings</a></br>
						<a class="res_paper_link" href="https://papers.nips.cc/paper/2012/file/e2c4a40d50b47094f571e40efead3900-Paper.pdf" target="_blank">Online Sum-Product Computation over Trees</a></td>
					</tr>
					<tr>
						<td colspan="2" class="phi_cell"><span class="phi">Φ</span><br></td>					
					</tr>
					
					<tr>
						<td class="res_first_col"><span class="subtitle">Clustering:</span><br>
						Clustering is similar to classification but without labels associated with the classes (in this case referred to as 'clusters'). In other words, the aim is to partition the set of items into clusters so that items in the same cluster are similar to each other in some way.
						</td>
						<td class="papers"><br><a class="res_paper_link" href="http://proceedings.mlr.press/v83/pasteris18a/pasteris18a.pdf" target="_blank">On Similarity Prediction and Pairwise Clustering</a><br>
						<a class="res_paper_link" href="http://proceedings.mlr.press/v30/Gentile13.pdf" target="_blank">Online Similarity Prediction of Networked Data from Known and Unknown Graphs</a><td>
							
					</tr>
					<tr>
						<td colspan="2" class="phi_cell"><span class="phi">Φ</span><br></td>					
					</tr>
					
					<tr>
						<td class="res_first_col"><span class="subtitle">Matrix Completion:</span><br>
						Matrix Completion is a classification problem where the items are the cells in a matrix (a table formed of rows and columns) where some kind of bias is assumed. For example: the labelings of a pair of rows or columns are likely to be similar to one another.
						</td>
						<td class="papers"><br><a class="res_paper_link" href="https://arxiv.org/pdf/1906.07255.pdf" target="_blank">Online Matrix Completion with Side Information</a><br>
						<a class="res_paper_link" href="https://papers.nips.cc/paper/2016/file/d46e1fcf4c07ce4a69ee07e4134bcef1-Paper.pdf" target="_blank">Mistake Bounds for Binary Matrix Completion</a><br>
						<a class="res_paper_link" href="https://www.jmlr.org/papers/volume16/herbster15a/herbster15a.pdf" target="_blank">Predicting a Switching Sequence of Graph Labelings</a></td>
						
					</tr>
					<tr>
						<td colspan="2" class="phi_cell"><span class="phi">Φ</span><br></td>					
					</tr>
					
					<tr>
						<td class="res_first_col"><span class="subtitle">Graph-Based Learning:</span><br>
						In Graph-Based Learning the items in the Machine Leaning task (for example, classification or clustering) are nodes in a network. It is assumed that items / nodes which are linked (for example, friends on a social media network) are likely to behave similarly with respect to the problem: for example, they are likely to have the same label (in the case of classification) or are likely to be in the same cluster (in the case of clustering).
						</td>
						<td class="papers"><br><a class="res_paper_link" href="https://arxiv.org/pdf/1906.07255.pdf" target="_blank">Online Matrix Completion with Side Information</a><br>
						<a class="res_paper_link" href="https://papers.nips.cc/paper/2015/file/cdf1035c34ec380218a8cc9a43d438f9-Paper.pdf" target="_blank">Online Prediction at the Limit of Zero Temperature</a><br>
						<a class="res_paper_link" href="https://www.jmlr.org/papers/volume16/herbster15a/herbster15a.pdf" target="_blank">Predicting a Switching Sequence of Graph Labelings</a></br>
						<a class="res_paper_link" href="http://proceedings.mlr.press/v30/Gentile13.pdf" target="_blank">Online Similarity Prediction of Networked Data from Known and Unknown Graphs</a></br>
						<a class="res_paper_link" href="https://papers.nips.cc/paper/2012/file/e2c4a40d50b47094f571e40efead3900-Paper.pdf" target="_blank">Online Sum-Product Computation over Trees</a></td>

					</tr>
					<tr>
						<td colspan="2" class="phi_cell"><span class="phi">Φ</span><br></td>					
					</tr>
					
					<tr>
						<td class="res_first_col"><span class="subtitle">Optimisation:</span><br>
						In Optimisation problems data is supplied to the learner, who is then required to make a complicated choice. The learner's choice then generates a reward (or penalty) which can be computed from the data and the choice. For many optimisation problems it is conjectured that there exist no fast algorithms to select the optimal choice. Hence, the aim is to design fast algorithms that make choices whose rewards approximate the optimal.
						</td>
						<td class="papers"><br><a class="res_paper_link" href="https://arxiv.org/pdf/1906.07055.pdf" target="_blank">Service Placement with Provable Guarantees in Heterogenous Edge Computing Systems</a><br>
						<a class="res_paper_link" href="https://shiqiang.wang/papers/SP_DAISWorkshop2017.pdf" target="_blank">Data Distribution and Scheduling for Distributed Analytics Tasks</a><td>
							
					</tr>
					<tr>
						<td colspan="2" class="phi_cell"><span class="phi">Φ</span><br></td>					
					</tr>
					
					<tr>
						<td class="res_first_col"><span class="subtitle">Multi-Task Learning:</span><br>
						In Multi-Task Learning many occurrences of the same learning problem are to be solved simultaneously. We call each occurrence a 'task'. It is assumed that there is some relationship between the tasks, in which information gained from one task can help us to solve another.
						</td>
						<td class="papers"><br><a class="res_paper_link" href="https://arxiv.org/pdf/2008.07055.pdf" target="_blank">Online Multitask Learning with Long-Term Memory</a><br>
						<a class="res_paper_link" href="https://arxiv.org/pdf/1906.07255.pdf" target="_blank">Online Matrix Completion with Side Information</a><br>
						<a class="res_paper_link" href="https://papers.nips.cc/paper/2016/file/d46e1fcf4c07ce4a69ee07e4134bcef1-Paper.pdf" target="_blank">Mistake Bounds for Binary Matrix Completion</a><br>
						<a class="res_paper_link" href="https://www.jmlr.org/papers/volume16/herbster15a/herbster15a.pdf" target="_blank">Predicting a Switching Sequence of Graph Labelings</a></br>
						<a class="res_paper_link" href="https://papers.nips.cc/paper/2012/file/e2c4a40d50b47094f571e40efead3900-Paper.pdf" target="_blank">Online Sum-Product Computation over Trees</a></td>
						
					</tr>
					<tr>
						<td colspan="2" class="phi_cell"><span class="phi">Φ</span><br></td>					
					</tr>
					
					<tr>
						<td class="res_first_col"><span class="subtitle">Location Problems:</span><br>
						Location Problems involve a set of locations. The learner must decide on an action to carry out at each location. For example: in the case that locations are towns the actions could correspond to whether or not to open a restaurant in each town. Alternatively in the case that the locations are network servers the actions could correspond to storing a set of applications on each server.
						</td>
						<td class="papers"><br><a class="res_paper_link" href="https://arxiv.org/pdf/2007.02801.pdf" target="_blank">Online Learning of Facility Locations</a><br>
						<a class="res_paper_link" href="https://arxiv.org/pdf/1810.11843.pdf" target="_blank">MaxHedge: Maximising a Maximum Online</a><br>
						<a class="res_paper_link" href="https://arxiv.org/pdf/1906.07055.pdf" target="_blank">Service Placement with Provable Guarantees in Heterogenous Edge Computing Systems</a></br>
						<a class="res_paper_link" href="https://shiqiang.wang/papers/SP_DAISWorkshop2017.pdf" target="_blank">Data Distribution and Scheduling for Distributed Analytics Tasks</a></td>

					</tr>
					<tr>
						<td colspan="2" class="phi_cell"><span class="phi">Φ</span><br></td>					
					</tr>
					
					<tr>
						<td class="res_first_col"><span class="subtitle">Graphical Models:</span><br>
						Graphical Models are probability distributions over many variables where the relationships (or 'conditional independences') between variables are represented by a network with nodes representing the variables. Given the knowledge of the states of some of the variables the aim is to determine the probability of whether a specific variable is in a given state.
						</td>
						<td class="papers"><br><a class="res_paper_link" href="https://papers.nips.cc/paper/2012/file/e2c4a40d50b47094f571e40efead3900-Paper.pdf" target="_blank">Online Sum-Product Computation over Trees</a><br>
						<a class="res_paper_link" href="http://www0.cs.ucl.ac.uk/staff/M.Herbster/pubs/mc14.pdf" target="_blank">Efficient Prediction for Tree Markov Random Fields in a Streaming Model</a><td>
					
					</tr>
					<tr>
						<td colspan="2" class="phi_cell"><span class="phi">Φ</span><br></td>					
					</tr>
					
					
					<tr id="last_row">
						<td class="res_first_col last_row"><span class="subtitle">Data-Structures:</span><br>
						Machine Learning algorithms work with data - both the input data and the data which is computed and used during the algorithmic process itself. The aim is to design algorithms that are fast; in that they don’t take long to run. To achieve this goal the data must be encoded and structured (in what is known as a 'data-structure') in such a way that an algorithm, which has been tailor-made to the data-structure, can process it quickly. 
						</td>
						<td class="papers"><br><a class="res_paper_link" href="https://arxiv.org/pdf/2008.07055.pdf" target="_blank">Online Multitask Learning with Long-Term Memory</a><br>
						<a class="res_paper_link" href="http://proceedings.mlr.press/v30/Gentile13.pdf" target="_blank">Online Similarity Prediction of Networked Data from Known and Unknown Graphs</a><br>
						<a class="res_paper_link" href="https://papers.nips.cc/paper/2012/file/e2c4a40d50b47094f571e40efead3900-Paper.pdf" target="_blank">Online Sum-Product Computation over Trees</a></br>	
						<a class="res_paper_link" href="http://www0.cs.ucl.ac.uk/staff/M.Herbster/pubs/mc14.pdf" target="_blank">Efficient Prediction for Tree Markov Random Fields in a Streaming Model</a><td>						
					</tr>

								
				</table>
				<img id="thesis_pic" src="Resources/Images/thesis.jpg" alt="Thesis">
			</article>
			<footer class="main_footer" id="quals_footer">
				<div class="contact">
				Dr Stephen Pasteris<br>
				Department of Computer Science<br>
				University College London<br>
				66-72 Gower Street<br>
				London WC1E 6BT<br>
				United Kingdom<br>
				</div>
				<div class="email">Email: <a href="mailto:s.pasteris@cs.ucl.ac.uk" id="email">s.pasteris@cs.ucl.ac.uk</a>
				</div>
			</footer>
		</div>
	</body>
</html>